= Assignment — Thermal Fin ROM (HPC) with Containers, Slurm & Surrogates
:navtitle: Assignment — Thermal Fin ROM
:description: Project brief for M2: build a reproducible HPC pipeline (Docker→GHCR→Apptainer→Slurm) to generate data, train a surrogate, quantify uncertainty, and package an inference CLI.
:icons: font
:source-highlighter: highlight.js
:stem: latexmath
:page-tags: assignment, m2, hpc, containers, apptainer, slurm, dvc, mlflow, feelpp, rom

== 0. Overview
You will implement an end-to-end, **reproducible HPC pipeline** that learns a **surrogate (ROM)** for the **2D thermal fin** problem. The pipeline must:

. Generate a dataset via an **ensemble campaign** (Slurm job arrays).
. Aggregate outputs to a single **Parquet** table.
. Train and evaluate a **surrogate model** (baseline: **Gaussian Process**; group-specific variant allowed).
. Track experiments (**MLflow**) and version data/pipeline (**DVC**).
. Package an **inference CLI** that returns **mean** and **uncertainty (std)** for a given parameter vector.

[IMPORTANT]
====
**Common dataset & infrastructure**, **different method per group** (to compare approaches fairly).
====

== 1. Learning goals
* Engineer a containerized research workflow: **Docker → GHCR → Apptainer** (cluster).
* Orchestrate ensembles with **Slurm** (`--array`, `--dependency`).
* Build reproducible pipelines with **DVC**; log metrics/artifacts with **MLflow** (file backend).
* Train a small-N surrogate and **quantify uncertainty**; report accuracy & calibration.
* Publish a final **image** and a **CLI** suitable for batch inference.

== 2. Problem (short spec)
Thermal fin, steady-state conduction with piecewise-constant conductivities and convective boundary conditions.

*Parameters*: latexmath:[$\mu=(k_1,k_2,k_3,k_4,\mathrm{Bi})$], with ranges:
latexmath:[$k_i\in[0.1,10.0],\ \mathrm{Bi}\in[0.01,1.0]$].
*QoI*: average root temperature latexmath:[$T_{\text{root}}(\mu)=\int_{\Gamma_{\text{root}}}u\,ds$].

Use the **starter generator (synthetic)** to validate the pipeline, then **replace** it with your **Feel++ wrapper** (recommended) when ready.

== 3. What we provide
* A **template repository** (starter) with:
  - `containers/Dockerfile`, `.dockerignore`
  - `.github/workflows/docker-build-push.yml` (build on tag to **GHCR**)
  - `hpc/*.sbatch` (arrays & deps)
  - `src/pipeline/`:
    * `generate/` (LHS params + synthetic `generate_point.py`)
    * `aggregate/merge.py`
    * `train/fit_gp.py` (GP baseline; MLflow optional)
    * `infer/cli.py` (returns mean/std)
  - `mlops/dvc.yaml`, `mlops/mlflow.conf`
  - `Makefile` (`mvp`, `gen`, `agg`, `train`, `best`, `infer`)
* A **problem statement** for the 2D fin (steady).

== 4. What you must deliver
. **Working pipeline** (local thin slice + HPC):  
  Docker image (buildable), Apptainer `.sif` (pullable), Slurm arrays (data generation), aggregated Parquet, training, evaluation.
. **Surrogate model** (one per group) with **UQ**:
  - Baseline GP is included; groups may choose one primary method:
    * RF/XGBoost, SVR, MLP, PCE (sparse), RB (POD–Galerkin), Multi-fidelity GP, or Active Learning.
. **Tracking & reproducibility**:
  - MLflow runs (metrics + model artifacts).
  - DVC stages (generate→aggregate→train→evaluate) runnable with `dvc repro`.
. **Inference CLI**:
  - `python -m pipeline.infer.cli --theta '{"k1":..,"k2":..,"k3":..,"k4":..,"Bi":..}'`
  - Prints `{"mean": <float>, "std": <float>}`.
. **Final image tag** on GHCR (e.g., `v1.0.0`) containing or mounting the trained model.
. **Short report (2–3 pages)**:
  - Data summary, model choice, hyper-params, **RMSE/NLL**, **calibration (coverage 95%)**, timings (train & infer), and limitations.

== 5. Technologies & constraints
* **Containers**: Docker (or Podman), non-root runtime. Registry: **GHCR** (tag on release).  
* **HPC containers**: **Apptainer** (user-space).  
* **Scheduler**: **Slurm** arrays + dependencies (`afterok`).  
* **Pipeline**: **DVC** (file backend; remote optional).  
* **Tracking**: **MLflow** (file backend; no server required).  
* **Data**: JSON shards → **Parquet** (pyarrow).  
* **Code**: Python 3.11, Poetry/uv, scikit-learn, pandas, joblib.  
* **Compute budget** (indicative): N≈300 train + 60 valid + 100 test (adjust to quota).  
* **Repro**: set seeds; pin threads on CPU (`OMP_NUM_THREADS=1`).

== 6. Milestones & deadlines
[cols="1,4,2", options="header"]
|===
|Milestone |Expected artifacts |Due

|M1 — MVP local
|`make mvp` runs end-to-end; `train.parquet` + `results/runs/0/gp_model.joblib`; 10-line log/screenshot
|Wk 1, end

|M2 — Image & CI
|Image built locally; tag `v0.1.0` → CI pushes to GHCR; link to GHCR image
|Wk 2, mid

|M3 — HPC generation
|`.sif` pulled; array generated N cases; aggregated Parquet on cluster
|Wk 3, end

|M4 — Tracking & training
|`mlops/dvc.yaml` valid; MLflow runs; best run identified
|Wk 4, mid

|M5 — Packaging & report
|Final tag `v1.0.0`; CLI inference works; PDF report (2–3 pages)
|Wk 5, end
|===

== 7. Repository rules (GitHub Classroom)
* Template repository: `course-project-m2-YYYYsX-finrom-template` (provided).
* Student repo name template: `course-project-m2-YYYYsX-finrom-<METHOD>-g<TEAM>`.
* Visibility: **Private**. Use **branches/PRs**; CI must be **green** before merge.
* Include **README** with exact commands to reproduce your results.

== 8. Grading rubric (indicative)
* **Engineering (20%)** — container hygiene, GHCR release, Apptainer run, Slurm arrays/deps.
* **Data pipeline (15%)** — ensemble produced, aggregation OK, DVC stages runnable.
* **Modeling (35%)** — surrogate correctness & stability, **RMSE/NLL**, **uncertainty calibration (coverage)**.
* **Tracking & reproducibility (15%)** — MLflow runs, seeds, documented commands, readme clarity.
* **Packaging & report (15%)** — inference CLI works; 2–3 page report with parity & calibration plots, timings.

== 9. Group methods — pick one primary
* **GP** (baseline; native UQ).  
* **RF/XGBoost** (fast, robust; UQ via quantile or bootstrap + conformal).  
* **SVR (RBF)** or **MLP** (UQ via ensembles or MC dropout + conformal).  
* **PCE (sparse)** (interpretable; Sobol indices).  
* **RB (POD–Galerkin)** (projection ROM; online timing + estimator or x-val).  
* **Multi-fidelity GP** (coarse + few fine samples).  
* **Active learning** (variance/EI acquisition).

== 10. Acceptance checks (must pass)
- [ ] `docker build` succeeds; `docker run … --help` prints usage.  
- [ ] Tagging `v0.x.y` triggers CI and pushes to GHCR.  
- [ ] `apptainer pull docker://…:tag` produces a `.sif` that runs.  
- [ ] `sbatch` array creates `data/raw/case_*.json`; aggregation writes `data/processed/train.parquet`.  
- [ ] Training logs metrics; a model artifact exists; best run identified.  
- [ ] CLI returns `{"mean": …, "std": …}` for a valid `--theta`.  
- [ ] Short report submitted; plots included; commands reproducible.

== 11. Academic integrity & teamwork
* Work in **teams of 2–3**. You may consult public docs, but your code, configs, and report must be your own.  
* Cite any external code or manuscripts. Plagiarism = 0.  
* Each PR should have meaningful messages; use issues for task tracking.

== 12. Getting started (quick commands)
[source,bash]
----
# Local thin slice
python -m pipeline.generate.make_params --n 60 --out data/params.jsonl
python -m pipeline.generate.run_many_local --params data/params.jsonl --outdir data/raw/
python -m pipeline.aggregate.merge --out data/processed/train.parquet
python -m pipeline.train.fit_gp --train data/processed/train.parquet --outdir results/runs/0
python -m pipeline.infer.cli --modeldir results/runs/0 --theta '{"k1":1,"k2":1,"k3":1,"k4":1,"Bi":0.1}'

# Build & publish image (CI on tag)
docker build -f containers/Dockerfile -t ghcr.io/ORG/REPO:local .
git tag v0.1.0 && git push origin v0.1.0

# On the cluster
module load apptainer
apptainer pull --name app.sif docker://ghcr.io/ORG/REPO:v0.1.0
sbatch hpc/generate_array.sbatch
sbatch hpc/aggregate.sbatch
sbatch hpc/train_array.sbatch
sbatch hpc/evaluate.sbatch
----

== 13. Feel++ integration (recommended)
Replace the synthetic generator by your Feel++ run:

. Build parameterized config/mesh from latexmath:[$\mu$].
. Solve the steady fin problem.
. Post-process latexmath:[$T_{\text{root}}=\int_{\Gamma_{\text{root}}}u\,ds$].
. Write one JSON line per case: `{case_id, k1..k4, Bi, QoI}`.

[NOTE]
====
If cluster time is tight: keep 2D as default. A small **3D** variant is allowed for demos or multi-fidelity (few high-fidelity points).
====

== 14. FAQ
* *Do we need a server for MLflow?* No, the file backend is sufficient.  
* *Where do we store large files?* Use DVC with a remote (S3/SSH/shared FS) or shared scratch.  
* *Can we switch method mid-project?* Yes, with a clear justification in the report and reproducible runs.
